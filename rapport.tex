\documentclass[12pt,a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{booktabs}
\usepackage{setspace}
\usepackage{listings}
\usepackage{xcolor}

\geometry{margin=2.5cm}
\onehalfspacing

\lstdefinestyle{mystyle}{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{teal},
  showstringspaces=false
}
\lstset{style=mystyle}

\title{
  \textbf{Projet Kaggle – Python pour l’Intelligence Artificielle}\\[0.4cm]
  Prédiction de la santé mentale
}
\author{
  Astride Saman\\
  Licence 3 Intelligence Artificielle\\
  Université Côte d'Azur
}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

% ========================
\chapter{Introduction au problème d'IA}
% ========================

Les troubles de la santé mentale, et en particulier la dépression, ont un impact majeur sur la qualité de vie, la réussite académique et l'insertion professionnelle.
Pouvoir identifier précocement les individus à risque est un enjeu important.

Dans ce projet, nous utilisons un jeu de données Kaggle pour prédire si une personne est dépressive (\texttt{Depression = 1}) ou non (\texttt{Depression = 0}) à partir d'informations personnelles, académiques et professionnelles.
Le problème est traité comme une \textbf{classification binaire supervisée}.

L'objectif est double :
\begin{itemize}
  \item construire un pipeline complet : prétraitement, modélisation, entraînement, évaluation, soumission Kaggle ;
  \item comparer un \textbf{modèle linéaire} simple et un \textbf{réseau de neurones} plus complexe.
\end{itemize}

\newpage

% ========================
\chapter{Présentation du jeu de données}
% ========================

\section{Fichiers Kaggle}

La compétition fournit trois fichiers CSV :
\begin{itemize}
  \item \texttt{train.csv} : contient les features + la cible \texttt{Depression} ;
  \item \texttt{test.csv} : mêmes features, sans la cible (servira pour Kaggle) ;
  \item \texttt{sample\_submission.csv} : gabarit de soumission, avec les colonnes \texttt{id} et \texttt{Depression}.
\end{itemize}

\section{Variable cible}

La variable cible, notée $y$, est la colonne :
\begin{itemize}
  \item \texttt{Depression} $\in \{0,1\}$.
\end{itemize}

\section{Variables explicatives}

\subsection*{Colonnes supprimées}
\begin{itemize}
  \item \texttt{id} : identifiant purement technique ;
  \item \texttt{Name} : texte libre, non utilisé.
\end{itemize}

\subsection*{Variables numériques}
\begin{itemize}
  \item \texttt{Age}
  \item \texttt{Academic Pressure}
  \item \texttt{Work Pressure}
  \item \texttt{CGPA}
  \item \texttt{Study Satisfaction}
  \item \texttt{Job Satisfaction}
  \item \texttt{Work/Study Hours}
  \item \texttt{Financial Stress}
\end{itemize}

\subsection*{Variables catégorielles}
\begin{itemize}
  \item \texttt{Gender}
  \item \texttt{City}
  \item \texttt{Working Professional or Student}
  \item \texttt{Profession}
  \item \texttt{Sleep Duration}
  \item \texttt{Dietary Habits}
  \item \texttt{Degree}
  \item \texttt{Have you ever had suicidal thoughts ?}
  \item \texttt{Family History of Mental Illness}
\end{itemize}

Une analyse exploratoire (non reproduite ici dans le détail) montre la présence de valeurs manquantes et un mélange de données numériques et catégorielles, ce qui motive un prétraitement soigné.

\newpage

% ========================
\chapter{Architecture du projet et fichiers}
% ========================

Le projet est organisé ainsi :

\begin{verbatim}
mental-health-prediction/
├── data/
│   ├── train.csv
│   ├── test.csv
│   └── sample_submission.csv
│
├── src/
│   ├── __init__.py
│   ├── dataset.py
│   ├── model.py
│   └── trainer.py
│
├── main.py
├── predict.py
└── rapport.tex
\end{verbatim}

\begin{itemize}
  \item \textbf{\texttt{src/dataset.py}} : définition du Dataset PyTorch.
  \item \textbf{\texttt{src/model.py}} : modèles (linéaire + réseau de neurones).
  \item \textbf{\texttt{src/trainer.py}} : prétraitement et classe d'entraînement.
  \item \textbf{\texttt{main.py}} : script principal d'entraînement et de comparaison.
  \item \textbf{\texttt{predict.py}} : script pour générer \texttt{submission.csv}.
\end{itemize}

Dans les sections suivantes, chaque fichier est détaillé avec le code et une explication ligne par ligne.

\newpage

% ========================
\chapter{Description détaillée du code}
% ========================

\section{Prétraitement : \texttt{load\_and\_preprocess} (\texttt{src/trainer.py})}

\begin{lstlisting}[language=Python, caption={Fonction de prétraitement}]
def load_and_preprocess(path: str):
    # 1) Chargement du CSV
    df = pd.read_csv(path)

    target_col = "Depression"

    # Suppression des colonnes non pertinentes
    df = df.drop(columns=["id", "Name"])

    # Séparation features / cible
    y = df[target_col].astype("float32").values
    X = df.drop(columns=[target_col])

    # Définition des listes de colonnes
    num_cols = [
        "Age",
        "Academic Pressure",
        "Work Pressure",
        "CGPA",
        "Study Satisfaction",
        "Job Satisfaction",
        "Work/Study Hours",
        "Financial Stress",
    ]

    cat_cols = [
        "Gender",
        "City",
        "Working Professional or Student",
        "Profession",
        "Sleep Duration",
        "Dietary Habits",
        "Degree",
        "Have you ever had suicidal thoughts ?",
        "Family History of Mental Illness",
    ]

    # Gestion des valeurs manquantes
    X[num_cols] = X[num_cols].fillna(X[num_cols].median())
    X[cat_cols] = X[cat_cols].fillna("Unknown")

    # Encodage one-hot
    X = pd.get_dummies(X, columns=cat_cols)
    feature_cols = X.columns.tolist()

    # Conversion en numpy float32
    X = X.astype("float32").values

    # Split train / validation
    np.random.seed(42)
    indices = np.random.permutation(len(X))
    split = int(0.8 * len(X))
    train_idx = indices[:split]
    val_idx = indices[split:]

    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]

    # Standardisation
    mean = X_train.mean(axis=0, keepdims=True)
    std = X_train.std(axis=0, keepdims=True) + 1e-8

    X_train = (X_train - mean) / std
    X_val   = (X_val   - mean) / std

    return X_train, y_train, X_val, y_val, mean, std, feature_cols
\end{lstlisting}

\paragraph{Explications détaillées :}
\begin{itemize}
  \item \textbf{Chargement} : on lit le fichier CSV dans un DataFrame \texttt{df}.
  \item \textbf{Suppression de colonnes} : \texttt{id} et \texttt{Name} n’apportent pas d'information utile.
  \item \textbf{Séparation cible / features} : \texttt{y} contient la cible en float32 (compatible PyTorch).
  \item \textbf{Listes de colonnes} : on sépare explicitement les colonnes numériques (\texttt{num\_cols}) et catégorielles (\texttt{cat\_cols}) pour appliquer un traitement adapté.
  \item \textbf{Valeurs manquantes} : médiane pour le numérique, catégorie spéciale \texttt{"Unknown"} pour le qualitatif.
  \item \textbf{One-hot encoding} : \texttt{pd.get\_dummies} transforme chaque modalité en colonne binaire.
  \item \textbf{Conversion en numpy} : PyTorch travaille plus facilement avec des tableaux \texttt{float32}.
  \item \textbf{Split train/val} : mélange aléatoire des indices puis découpage 80/20.
  \item \textbf{Standardisation} : calcul de la moyenne et de l’écart-type uniquement sur le train, puis application au train et à la validation.
  \item \textbf{Retour} : on renvoie les matrices prêtes à être utilisées par les modèles ainsi que les paramètres \texttt{mean}, \texttt{std} et \texttt{feature\_cols}, qui seront réutilisés dans \texttt{predict.py}.
\end{itemize}

\section{Dataset PyTorch : \texttt{MentalDataset} (\texttt{src/dataset.py})}

\begin{lstlisting}[language=Python, caption={Classe Dataset}]
class MentalDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]
\end{lstlisting}

\paragraph{Explications :}
\begin{itemize}
  \item \textbf{\_\_init\_\_} : on stocke les features et la cible dans des tenseurs PyTorch.
  \item \textbf{\_\_len\_\_} : retourne le nombre d’exemples.
  \item \textbf{\_\_getitem\_\_} : permet à un \texttt{DataLoader} de récupérer $(X_i, y_i)$ pour un indice donné.
\end{itemize}

\section{Modèles : \texttt{LinearBaseline} et \texttt{MentalHealthModelNN} (\texttt{src/model.py})}

\subsection{Modèle linéaire}

\begin{lstlisting}[language=Python, caption={Modèle linéaire}]
class LinearBaseline(nn.Module):
    def __init__(self, input_dim: int):
        super().__init__()
        self.linear = nn.Linear(input_dim, 1)

    def forward(self, x):
        return torch.sigmoid(self.linear(x))
\end{lstlisting}

\paragraph{Explications :}
\begin{itemize}
  \item C’est une régression logistique : couche linéaire + sigmoïde.
  \item Paramètres : vecteur de poids $w \in \mathbb{R}^d$ et biais $b$.
  \item La sortie est une probabilité $\hat{y} \in [0,1]$.
\end{itemize}

\subsection{Réseau de neurones}

\begin{lstlisting}[language=Python, caption={Réseau de neurones}]
class MentalHealthModelNN(nn.Module):
    def __init__(self, input_dim: int):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1),
            nn.Sigmoid(),
        )

    def forward(self, x):
        return self.net(x)
\end{lstlisting}

\paragraph{Explications :}
\begin{itemize}
  \item Architecture MLP avec deux couches cachées (128 et 64 neurones).
  \item \textbf{ReLU} : introduit de la non-linéarité.
  \item \textbf{Dropout(0.3)} : désactive aléatoirement 30\% des neurones pour limiter l’overfitting.
  \item \textbf{Sigmoid} : transforme la dernière sortie en probabilité entre 0 et 1.
\end{itemize}

\section{Entraîneur : \texttt{MentalHealthTrainer} (\texttt{src/trainer.py})}

\begin{lstlisting}[language=Python, caption={Classe d'entraînement}]
@dataclass
class MentalHealthTrainer:
    batch_size: int
    n_epochs: int
    eval_samples: int

    def train(
        self,
        model: nn.Module,
        train_set: MentalDataset,
        val_set: MentalDataset,
        optimizer: optim.Optimizer,
        device: torch.device,
        model_name: str = "model",
    ) -> float:
        model.to(device)
        best_val = 0.0
        patience = 3
        counter = 0

        train_loader = DataLoader(
            train_set,
            batch_size=self.batch_size,
            shuffle=True,
            drop_last=False,
        )

        for epoch in range(self.n_epochs):
            model.train()
            train_loss, train_acc, n_train = 0.0, 0.0, 0

            for X_batch, y_batch in train_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)

                optimizer.zero_grad()
                preds = model(X_batch)
                loss = F.binary_cross_entropy(preds, y_batch)
                loss.backward()
                optimizer.step()

                bs = X_batch.size(0)
                predicted = (preds >= 0.5).float()
                acc = (predicted == y_batch).float().mean().item()

                train_loss += loss.item() * bs
                train_acc  += acc * bs
                n_train    += bs

            train_loss /= n_train
            train_acc  /= n_train

            metrics_train = self.eval(model, train_set, device)
            metrics_val   = self.eval(model, val_set, device)
            val_acc       = metrics_val["accuracy"]

            print(
                f"[{model_name}] Epoch {epoch+1:02d} | "
                f"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | "
                f"Eval Train Acc: {metrics_train['accuracy']:.4f} | "
                f"Eval Val Acc: {metrics_val['accuracy']:.4f}"
            )

            # Early stopping + sauvegarde
            if val_acc > best_val:
                best_val = val_acc
                counter = 0
                torch.save(model.state_dict(),
                           f"best_model_weights_{model_name}.pt")
            else:
                counter += 1
                if counter >= patience:
                    print(f"Early stopping for {model_name}.")
                    break

        return best_val

    @torch.inference_mode
    def eval(self, model: nn.Module, dataset: MentalDataset,
             device: torch.device) -> dict:
        model.eval()
        loader = DataLoader(dataset,
                            batch_size=self.batch_size,
                            shuffle=True)
        accs, losses = [], []

        for X_batch, y_batch in loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            preds = model(X_batch)
            loss = F.binary_cross_entropy(preds, y_batch, reduction="none")

            predicted = (preds >= 0.5).float()
            acc = (predicted == y_batch).float()

            losses.append(loss)
            accs.append(acc)

        acc_tensor  = torch.cat(accs).mean()
        loss_tensor = torch.cat(losses).mean()

        return {
            "accuracy": float(acc_tensor),
            "loss": float(loss_tensor),
        }
\end{lstlisting}

\paragraph{Explications :}
\begin{itemize}
  \item La classe est un \textbf{dataclass} : plus pratique pour stocker \texttt{batch\_size}, \texttt{n\_epochs}, etc.
  \item \textbf{\texttt{train}} :
        \begin{itemize}
          \item place le modèle sur le bon device (\texttt{cpu} ou \texttt{cuda}) ;
          \item crée un \texttt{DataLoader} avec mélange des données ;
          \item boucle sur les epochs et les mini-batchs ;
          \item calcule la loss BCE et fait la rétropropagation ;
          \item accumule accuracy et loss moyennes ;
          \item évalue sur train et validation via \texttt{eval} ;
          \item applique un \textbf{early stopping} avec patience = 3 et sauvegarde les meilleurs poids dans un fichier.
        \end{itemize}
  \item \textbf{\texttt{eval}} :
        \begin{itemize}
          \item met le modèle en mode évaluation ;
          \item calcule loss et accuracy sans rétropropagation ;
          \item renvoie un dictionnaire avec \texttt{accuracy} et \texttt{loss}.
        \end{itemize}
\end{itemize}

\section{Script principal d'entraînement : \texttt{main.py}}

\begin{lstlisting}[language=Python, caption={Script d'entraînement}]
from src.trainer import MentalHealthTrainer, load_and_preprocess
from src.dataset import MentalDataset
from src.model import LinearBaseline, MentalHealthModelNN

import torch
import torch.optim as optim

def main():
    # 1) Prétraitement
    X_train, y_train, X_val, y_val, mean, std, feature_cols = \
        load_and_preprocess("./data/train.csv")

    train_set = MentalDataset(X_train, y_train)
    val_set   = MentalDataset(X_val, y_val)

    input_dim = X_train.shape[1]
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    trainer = MentalHealthTrainer(
        batch_size=64,
        n_epochs=25,
        eval_samples=10_000,
    )

    # 2) Définition des modèles
    models = {
        "linear": LinearBaseline(input_dim),
        "nn":     MentalHealthModelNN(input_dim),
    }

    val_scores = {}

    # 3) Entraînement et comparaison
    for name, model in models.items():
        optimizer = optim.Adam(model.parameters(),
                               lr=1e-3, weight_decay=1e-4)
        best_val = trainer.train(model, train_set, val_set,
                                 optimizer, device, model_name=name)
        val_scores[name] = best_val

    # 4) Affichage tableau
    print("\n=== Model comparison ===")
    for name, acc in val_scores.items():
        print(f"{name}: {acc:.4f}")

    # 5) Sélection du meilleur
    best_name = max(val_scores, key=val_scores.get)
    best_state_dict = torch.load(f"best_model_weights_{best_name}.pt",
                                 map_location="cpu")

    # 6) Sauvegarde globale pour predict.py
    torch.save(
        {
            "model_type": best_name,
            "state_dict": best_state_dict,
            "mean": mean,
            "std": std,
            "feature_cols": feature_cols,
        },
        "mental_health_model.pt",
    )

if __name__ == "__main__":
    main()
\end{lstlisting}

\paragraph{Explication :}
\begin{itemize}
  \item \textbf{Étape 1} : prétraitement des données.
  \item \textbf{Étape 2} : création des deux modèles à comparer.
  \item \textbf{Étape 3} : entraînement de chaque modèle, stockage des meilleures accuracies validation.
  \item \textbf{Étape 4} : affichage d’un mini-tableau de comparaison.
  \item \textbf{Étape 5} : choix du meilleur modèle (score max en validation).
  \item \textbf{Étape 6} : sauvegarde d’un fichier unique \texttt{mental\_health\_model.pt} utilisé ensuite par \texttt{predict.py}.
\end{itemize}

\section{Prédiction Kaggle : \texttt{predict.py}}

\begin{lstlisting}[language=Python, caption={Script de prédiction pour Kaggle}]
from src.trainer import load_and_preprocess
from src.model import LinearBaseline, MentalHealthModelNN
from src.pred import preprocess_test  # si défini séparément

import torch
import pandas as pd
import numpy as np

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1) Charger les paramètres globaux
    ckpt = torch.load("mental_health_model.pt", map_location=device)
    model_type   = ckpt["model_type"]
    state_dict   = ckpt["state_dict"]
    mean         = ckpt["mean"]
    std          = ckpt["std"]
    feature_cols = ckpt["feature_cols"]

    # 2) Charger les données de test
    df_test   = pd.read_csv("./data/test.csv")
    df_sample = pd.read_csv("./data/sample_submission.csv")

    # 3) Prétraitement du test
    X_test = preprocess_test(df_test, feature_cols)
    X_test = (X_test - mean) / (std + 1e-8)

    # 4) Instancier le bon modèle
    input_dim = len(feature_cols)
    if model_type == "linear":
        model = LinearBaseline(input_dim)
    else:
        model = MentalHealthModelNN(input_dim)

    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()

    # 5) Prédiction
    with torch.inference_mode():
        X_tensor = torch.from_numpy(
            np.asarray(X_test, dtype="float32")
        ).to(device)
        probs = model(X_tensor).cpu().numpy().reshape(-1)
        preds = (probs >= 0.5).astype(int)

    # 6) Création du fichier de soumission
    submission = df_sample.copy()
    submission["Depression"] = preds
    submission.to_csv("submission.csv", index=False)

if __name__ == "__main__":
    main()
\end{lstlisting}

\paragraph{Explications :}
\begin{itemize}
  \item \textbf{Checkpoint} : on recharge le type de modèle, les poids et les paramètres du prétraitement.
  \item \textbf{Prétraitement test} : mêmes étapes que pour le train (alignement de colonnes + standardisation).
  \item \textbf{Choix du modèle} : si le meilleur modèle validé est le linéaire, on utilise \texttt{LinearBaseline}, sinon \texttt{MentalHealthModelNN}.
  \item \textbf{Prédiction} : application du modèle, seuil 0.5 sur les probabilités.
  \item \textbf{Soumission} : écriture du fichier \texttt{submission.csv} au format imposé par Kaggle.
\end{itemize}

\newpage

% ========================
\chapter{Modélisation mathématique}
% ========================

\section{Fonction de perte}

La fonction de perte utilisée est l'entropie croisée binaire :
\[
\mathcal{L}(y, \hat{y}) = -\left[ y \log(\hat{y}) + (1-y)\log(1-\hat{y}) \right]
\]
où :
\begin{itemize}
  \item $y \in \{0,1\}$ est la vraie étiquette,
  \item $\hat{y} \in [0,1]$ est la probabilité prédite.
\end{itemize}

\section{Optimisation (Adam)}

L’optimiseur Adam met à jour les paramètres $\theta$ en combinant :
\begin{itemize}
  \item une moyenne exponentielle des gradients,
  \item une moyenne exponentielle des gradients au carré.
\end{itemize}

L’implémentation PyTorch est :
\begin{lstlisting}[language=Python]
optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
\end{lstlisting}

Le terme \texttt{weight\_decay} correspond à une régularisation L2 :
\[
\mathcal{L}_{total} = \mathcal{L}_{BCE} + \lambda \lVert w \rVert_2^2
\]

\section{Métrique : accuracy}

On calcule :
\[
\text{Accuracy} = \frac{\#\{ i \;|\; \hat{y}_i = y_i \}}{N}
\]

En code :
\begin{lstlisting}[language=Python]
predicted = (preds >= 0.5).float()
acc = (predicted == y_batch).float().mean().item()
\end{lstlisting}

\newpage

% ========================
\chapter{Résultats expérimentaux}
% ========================

\section{Performances train / validation}

Après entraînement, on obtient typiquement :

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Modèle} & \textbf{Accuracy train} & \textbf{Accuracy validation} \\
\midrule
Modèle linéaire & $\approx 0{,}91$ & $\approx 0{,}90$ \\
Réseau de neurones & $\approx 0{,}94$ & $\approx 0{,}94$ \\
\bottomrule
\end{tabular}
\caption{Comparaison des performances des modèles}
\end{table}

\section{Courbes de convergence}

\textbf{À insérer ici :} capture d’écran de la console montrant l’évolution de la loss et de l’accuracy par epoch.

\section{Analyse}

\begin{itemize}
  \item le modèle linéaire fournit une baseline correcte ;
  \item le réseau de neurones, grâce à sa capacité de modéliser des relations non linéaires, améliore nettement la précision ;
  \item la proximité des scores train/val montre un sur-apprentissage limité.
\end{itemize}

\newpage

% ========================
\chapter{Résultats Kaggle}
% ========================

\section{Scores obtenus}

Après génération de \texttt{submission.csv}, le fichier est soumis sur Kaggle.

Les scores calculés sont :
\begin{itemize}
  \item \textbf{Public Score} : 0.93827
  \item \textbf{Private Score} : 0.93759
\end{itemize}

\section{Statut "Unranked"}

La soumission ayant été effectuée \emph{après} la date limite officielle de la compétition, Kaggle affiche le statut :
\begin{center}
\texttt{Unranked / 2685}
\end{center}

Cela signifie :
\begin{itemize}
  \item la performance est bien calculée sur le test set officiel ;
  \item mais le compte n’est pas intégré au classement final public.
\end{itemize}

\section{Capture d’écran Kaggle}

\textbf{À insérer ici :}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{score_kaggle.png}
\caption{Capture d'écran du score Kaggle (statut Unranked)}
\label{fig:kaggle}
\end{figure}

\newpage

% ========================
\chapter{Difficultés rencontrées et corrections apportées}
% ========================

\section{Imports Python et architecture}

\begin{itemize}
  \item Erreurs de type \texttt{ModuleNotFoundError: No module named 'dataset'}.
  \item Résolution : réorganisation du projet en package \texttt{src/} avec \texttt{\_\_init\_\_.py} et imports explicites \texttt{from src.dataset import ...}.
\end{itemize}

\section{Alignement des colonnes train / test}

Après \texttt{get\_dummies}, certaines colonnes pouvaient exister dans le train mais pas dans le test (ou inversement).

Solution :
\begin{itemize}
  \item sauvegarder \texttt{feature\_cols} lors du prétraitement train ;
  \item dans \texttt{predict.py}, faire un \texttt{reindex} du test sur ces colonnes, en remplissant les colonnes manquantes par 0.
\end{itemize}

\section{Sur-apprentissage}

\begin{itemize}
  \item Problème : légère dérive train/val en augmentant trop le nombre d’epochs.
  \item Solutions :
        \begin{itemize}
          \item Dropout,
          \item weight decay,
          \item early stopping avec patience.
        \end{itemize}
\end{itemize}

\section{Captures d’écran à insérer}

\begin{itemize}
  \item Erreur d’import dans VS Code,
  \item Logs de la boucle d’entraînement,
  \item Interface Kaggle montrant le statut Unranked.
\end{itemize}

\newpage

% ========================
\chapter{Conclusion}
% ========================

Ce projet a permis de mettre en place un pipeline complet de Machine Learning et de deep learning pour un problème réel de prédiction de la dépression à partir de données tabulaires.

Les principales étapes réalisées sont :
\begin{itemize}
  \item Analyse et prétraitement du jeu de données Kaggle,
  \item Mise en place d’un \textbf{modèle linéaire} de référence,
  \item Implémentation d’un \textbf{réseau de neurones} régularisé en PyTorch,
  \item Entraînement, validation, comparaison des modèles,
  \item Génération et soumission d’un fichier \texttt{submission.csv} sur Kaggle.
\end{itemize}

Le réseau de neurones obtient un score Kaggle d’environ 0.94, confirmant sa capacité à généraliser sur des données non vues. Le travail montre la maîtrise :

\begin{itemize}
  \item des concepts d’apprentissage supervisé,
  \item de l’implémentation PyTorch,
  \item de l’évaluation (train/val/Kaggle),
  \item de la structuration de code pour un projet d’IA.
\end{itemize}

Des améliorations possibles incluent :
\begin{itemize}
  \item la recherche plus systématique d’hyperparamètres,
  \item l’exploration d’autres architectures pour données tabulaires,
  \item des méthodes d’interprétabilité (importance des variables, SHAP, etc.).
\end{itemize}

\end{document}
