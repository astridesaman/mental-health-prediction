# Mental Health Prediction ğŸ§   
*Projet de classification binaire en intelligence artificielle*

---

## ğŸ¯ Objectif du projet

Ce projet vise Ã  prÃ©dire si une personne prÃ©sente un risque de dÃ©pression (`Depression = 1`) ou non (`Depression = 0`) Ã  partir de caractÃ©ristiques personnelles, acadÃ©miques, professionnelles et sociales.

Lâ€™objectif est double :

- Appliquer un pipeline complet de Machine Learning avec PyTorch
- Construire un modÃ¨le performant, interprÃ©table et reproductible
- Soumettre les prÃ©dictions dans une compÃ©tition Kaggle rÃ©elle

---

## ğŸ“ Arborescence du projet


---

## ğŸ§  Description des donnÃ©es

Le jeu de donnÃ©es contient :

### Variables numÃ©riques :
- Ã‚ge
- Pression acadÃ©mique et professionnelle
- Note moyenne (CGPA)
- Satisfaction (Ã©tudes / travail)
- Nombre dâ€™heures de travail / Ã©tudes
- Niveau de stress financier

### Variables catÃ©gorielles :
- Genre
- Ville
- Statut (Ã©tudiant / professionnel)
- Profession
- QualitÃ© du sommeil
- Habitudes alimentaires
- DiplÃ´me
- PensÃ©es suicidaires (oui / non)
- AntÃ©cÃ©dents familiaux de troubles mentaux

### Variable cible :
- `Depression` : 0 = non dÃ©pressif, 1 = dÃ©pressif

---

## âš™ï¸ Pipeline de traitement

### 1. PrÃ©traitement
- Suppression des colonnes inutiles (`id`, `Name`)
- Remplissage des valeurs manquantes :
  - mÃ©diane pour les variables numÃ©riques
  - `"Unknown"` pour les variables catÃ©gorielles
- Encodage one-hot des variables catÃ©gorielles
- Normalisation des variables numÃ©riques (standardisation)
- SÃ©paration train / validation : 80% / 20%

---

### 2. ModÃ¨le utilisÃ©

Architecture de rÃ©seau de neurones (MLP) :

Input â†’ Linear(128) â†’ ReLU â†’ Dropout
â†’ Linear(64) â†’ ReLU â†’ Dropout
â†’ Linear(1) â†’ Sigmoid


- Nombre de paramÃ¨tres : **53 889**
- Fonction de perte : `Binary Cross Entropy`
- Optimiseur : Adam + rÃ©gularisation L2 (`weight_decay`)
- Batch size : 64
- Fonction de dÃ©cision : seuil Ã  0.5

---

### 3. EntraÃ®nement

- MÃ©trique principale : Accuracy
- Early stopping activÃ© pour Ã©viter lâ€™overfitting
- Sauvegarde automatique des meilleurs poids

---

## ğŸ“Š RÃ©sultats obtenus

Sur lâ€™ensemble de validation :

- **Accuracy Validation â‰ˆ 94.3%**
- TrÃ¨s faible overfitting
- Bonne gÃ©nÃ©ralisation
- Courbe de convergence stable

Sur Kaggle :
- Score public proche de **94%**
- Performance solide pour un projet acadÃ©mique en IA

---

## ğŸ” ProblÃ¨mes rencontrÃ©s et solutions

### 1. ProblÃ¨mes d'import des modules
RÃ©solu en structurant le projet avec `src/` et `__init__.py`

### 2. Valeurs manquantes
RÃ©solu via imputation automatique

### 3. CatÃ©gories inconnues dans test
RÃ©solu par rÃ©alignement des colonnes avec `reindex()`

### 4. Sur-apprentissage
RÃ©solu par :
- Dropout
- RÃ©gularisation L2
- Early stopping

---

## Comment lancer le projet

### EntraÃ®ner le modÃ¨le :

```bash
python main.py
```

### âœ… Technologies utilisÃ©es

- Python 3.13

- PyTorch

- pandas / numpy

- VS Code

- Kaggle

### âœ¨ Conclusion

Ce projet dÃ©montre la capacitÃ© Ã  :

- Construire un pipeline ML complet

- GÃ©rer des donnÃ©es rÃ©elles

- ImplÃ©menter un modÃ¨le de deep learning

- Ã‰valuer et rÃ©gulariser un rÃ©seau neuronal

- DÃ©ployer un modÃ¨le sur Kaggle

Il constitue une base solide pour des projets plus avancÃ©s en :

- IA mÃ©dicale

- Data science

- Machine Learning appliquÃ© Ã  la santÃ©

### ğŸ‘©â€ğŸ’» Auteur

- Projet rÃ©alisÃ© par : Astride SAMAN et Aya BOUROUISSE
- Licence Informatique 3 â€“ Intelligence Artificielle
- UniversitÃ© CÃ´te dâ€™Azur